{
  "researcher_model": "sonnet",
  "planner_model": "opus",
  "checker_model": "sonnet",
  "research_enabled": true,
  "plan_checker_enabled": true,
  "commit_docs": true,
  "phase_found": true,
  "phase_dir": ".planning/phases/12.1-bass-variation",
  "phase_number": "12.1",
  "phase_name": "bass-variation",
  "phase_slug": "bass-variation",
  "padded_phase": "12.1",
  "has_research": false,
  "has_context": false,
  "has_plans": false,
  "plan_count": 0,
  "planning_exists": true,
  "roadmap_exists": true,
  "state_content": "# ITM Project State\n\n## Current Status\n\n- **Phase**: Phase 16: Voice & Percussion Interactive Training\n- **Status**: ðŸŸ¢ Initializing Phase 16\n- **Next Milestone**: Sing-to-Answer in FET + Clap-to-Perform in Rhythm Architect\n- **Overall Progress**: ~92%\n\n## Active Requirements\n\n- [âœ…] REQ-MA-01: Pitch Stabilization (Confidence + Median + Hysteresis)\n- [âœ…] REQ-MA-02: Worklet Writes Stabilized Pitch\n- [âœ…] REQ-MA-03: Frequency-to-Note and Perfect Intonation\n- [âœ…] REQ-MA-04: Jazz Instrument Presets\n- [âœ…] REQ-MA-05: Optional Center-of-Gravity / Viterbi (doc)\n- [âœ…] REQ-SMR-01: Repetition Penalty System\n- [âœ…] REQ-SMR-02: Pattern-Specific Resilience\n- [âœ…] REQ-SMR-03: Stateful Weighted Selection\n- [âœ…] REQ-PRO-01: Grip Dictionary Harmony\n- [âœ…] REQ-PRO-02: Phrase Template Rhythm\n- [âœ…] REQ-PRO-03: Rhythmic Anticipation (The \"Push\")\n- [âœ…] REQ-PRO-04: Bass-Assist Integration\n- [âœ…] REQ-PRO-05: Pivot Rule Normalization\n- [âœ…] REQ-ARE-01: BPM-Aware Pattern Selection\n- [ ] REQ-APE-01: Voice-Leading Engine\n- [ ] REQ-APE-02: Chord DNA Model\n- [ ] REQ-APE-03: Register Management (Soprano Anchor)\n- [ ] REQ-APE-04: Tritone Substitution\n- [âœ…] REQ-FB-01: Guided Practice Sessions\n- [âœ…] REQ-FB-02: Active Scoring Logic\n- [âœ…] REQ-FB-03: Nano-Powered Critique\n- [âœ…] REQ-FB-04: Real-time Visual Heatmap\n- [âœ…] REQ-FB-05: High-Performance Pitch Engine (WASM-Equivalent MPM + Worklets)\n\n## Recent Achievements\n\n- **Completed Phase 14: Pitch Detection Latency (Break the Latency Wall)**:\n  - 16 kHz downsampling in worklet (native circular buffer, linear-interp to 1024); MPM at effective 16 kHz.\n  - Zero-copy circular buffer; hop size 128; inference every block once buffer full; pre-allocated tempNative, downsampled, nsdf.\n  - Optional hopBlocks throttle; CREPE-Tiny/Small swap path documented in RESEARCH.md; no console in worklet.\n- **Completed Phase 11: Pro Drum Engine (DeJohnette-Style)**:\n  - Implemented `DrumEngine` with \"Elastic\" Ride, \"Chatter\" Snare/Kick, and \"Hi-Hat\" Anchor.\n  - Added collaborative dynamics: drummer listens and simplifies when piano density is high.\n  - Implemented micro-timing (Ride Push / Snare Drag) for an organic \"pocket.\"\n  - Verified with 120Hz React bridge integration in `useJazzBand.ts`.\n- **Completed Phase 10: State-Machine Rhythmic Phrasing**:\n    - Upgraded `RhythmEngine` with a deep pattern history and Markov transition biases.\n    - Implemented exponential repetition penalties to force varied phrasing.\n    - Integrated adaptive energy/activity levels from the UI to drive rhythmic density.\n    - Verified rhythmic variety and \"Push\" (anticipation) logic with automated Vitest suite.\n- Defined the 4-phase roadmap for ITM 2026.\n- Established the core tech stack for scoring (Zustand + Tonal.js + Pitch Detection).\n- Built the \"Teaching Machine\" 15-minute routine engine.\n- Integrated real-time Performance Heatmaps into the Lead Sheet.\n- Automated AI-driven performance critique using Gemini Nano.\n- **Implemented Professional Microphone Pipe**: Audio Worklet + SharedArrayBuffer + McLeod Pitch Method.\n- **Enabled Zero-Latency Feedback**: 120Hz React bridge to the background audio thread.\n- **Completed Phase 9: Mic Algorithm Upgrade**:\n    - Implemented `CrepeStabilizer` (confidence gate, median filter, hysteresis) in TypeScript and Audio Worklet.\n    - Added `frequencyToNote` metadata (note name, cents deviation, perfect intonation indicator).\n    - Integrated Jazz Instrument Presets (Double Bass, Sax, Trumpet, etc.) with frequency clamping.\n    - Upgraded `useITMPitchStore` and `useHighPerformancePitch` for stabilized data.\n    - Verified stabilization logic with unit tests.\n- **Completed Phase 2: The \"Mastery Tree\"**:\n  - Implemented Song Tagging System for harmonic complexity.\n  - Built Visual Progress Tree UI component for song progression.\n  - Implemented Key Cycle Routine logic for tracking mastery across keys.\n- **Completed Phase 3: The \"Sonic\" Layer**:\n  - Premium Mixer (Bass, Drums, Piano volume + Mute/Solo), Master Limiter/EQ in globalAudio.\n  - Note Waterfall wired to band engine with Transport sync and harmonic coloring.\n  - ToneSpectrumAnalyzer and Acoustic Feedback (Warmth/Brightness) for mic tone analysis.\n- **Completed Phase 4: Cloud & Community**:\n  - Supabase client, schema (profiles, song_progress, classrooms, classroom_students, licks), RLS.\n  - Auth (sign-in/sign-up, AuthProvider, ensureProfile), progress sync (useSupabaseProgressSync, SyncBridge).\n  - Teacher Dashboard (classrooms, invite code, StudentProgressView), teacher nav when role=teacher.\n  - Lick Feed (publish from LickLibrary, LickFeed + Copy to library, /lick-feed route).\n  - PWA: manifest (Chord Lab, icons), vite-plugin-pwa service worker.\n- **Completed Phase 5: The Director Engine**:\n  - FSRS (ts-fsrs): directorTypes, useDirectorStore (persist), fsrsBridge (getState, recordReview, recordReviewFromOutcome, getDueItems, getNextNewItems).\n  - DirectorService.getNextDecision; useDirector hook; JazzKiller \"Suggested next\" button (song + key from Director).\n  - directorInstrumentSignal; globalAudio celloSynth, getGuideInstrument, playGuideChord; JazzKiller band uses guide instrument (Piano â†’ Cello â†’ Synth rotation).\n\n## Stabilization (Phase 6 prep)\n\n- **High-Performance Ear (2026)**:\n  - `PitchMemory.ts`: createPitchMemory() for 8-byte SAB (frequency + confidence); used by ITM pitch store.\n  - `public/worklets/pitch-processor.js`: Audio Worklet with MPM; **Phase 14**: zero-copy circular buffer, 16 kHz downsampling, hop 128; writes to SAB; CREPE-WASM-ready.\n  - useITMPitchStore loads `/worklets/pitch-processor.js` and passes sab + sampleRate in processorOptions for low-latency pitch.\n  - usePitchTracker hook for standalone pitch ref (polls SAB in rAF).\n  - COOP/COEP in vite server and preview for SharedArrayBuffer.\n- **JazzKiller playback**: initGlobalAudio() called on first play (togglePlayback) when !isAudioReady() so Director guide instrument works.\n- **AI detection**: checkAiAvailability() and isAiApiPresent(); navigator.languageModel checked first (Chrome canary); jazzTeacherLogic and nanoHelpers aligned.\n- **Chord analysis**: Functional decomposition (detectJazzChordByProfile) + CHORD_PC_TEMPLATES; Emaj7#5 and jazz alterations covered.\n- **Automated tests**: PitchMemory.test.ts, aiDetection (incl. isAiApiPresent), chordDetection (48 tests passing).\n\n## Phase 9: Mic Algorithm Upgrade (planned)\n\n- **Scope**: CrepeStabilizer (confidence gate, running median, hysteresis); in-worklet stabilization; usePitchTracker/ITM consume stabilized SAB; frequencyToNote + perfect intonation (Â±10 cents); jazz instrument presets (frequency clamping); tests.\n- **Planning**: `.planning/phases/09-mic-algorithm-upgrade/PLAN.md`, RESEARCH.md. ROADMAP and REQUIREMENTS updated (REQ-MA-01â€“REQ-MA-05).\n\n## Phase 14: Pitch Detection Latency (Break the Latency Wall) âœ…\n\n- **Status**: Completed.\n- **Scope**: 16 kHz downsampling in worklet; zero-copy circular buffer; hop size 128; pre-allocated buffers; optional hopBlocks throttle; CREPE-Tiny/Small swap path documented.\n- **Planning**: `.planning/phases/14-pitch-latency/PLAN.md`, RESEARCH.md, SUMMARY.md, VERIFICATION.md.\n- **Delivered**: pitch-processor.js updated with native circular buffer, linear-interp downsampler, MPM at 16 kHz effective, inference every block (or every hopBlocks); no GC in hot path; no console in worklet. CREPE swap path in RESEARCH.md.\n\n## Phase 12: Walking Bass Engine (Target & Approach)\n\n- **Status**: Implemented.\n- **WalkingBassEngine**: 4-beat strategy (Anchor â†’ Bridge â†’ Bridge â†’ Approach); Beat 4 chromatic or 5th-of-destination; E1â€“G3 range; tonal.js Chord/Note.\n- **Band integration**: useJazzBand generates full line at beat 0, plays `line[beat]` for 0â€“3; fallback to JazzTheoryService.getNextWalkingBassNote if line invalid.\n- **Tests**: WalkingBassEngine.test.ts (4 notes, range, Beat 1 root, Beat 4 approach, state carry).\n\n## Phase 13: Standards-Based Exercises (Scales, Guide Tones, Arpeggios) âœ…\n\n- **Status**: Completed.\n- **Goal**: **New module inside JazzKiller**: timed exercises over the standards (scales, guide tones, arpeggios) in sync with playback and chart; support both mic and MIDI input. Same standard picker, same lead sheet, same band.\n- **Delivered**: ExerciseInputAdapter (mic/MIDI â†’ getCurrentNote), StandardsExerciseEngine (getTargetSet + scoreNote), useStandardsExercise hook, StandardsExercisesPanel, JazzKiller integration (Exercises button, sidebar, panel). Unit tests: StandardsExerciseEngine.test.ts (8 passing).\n- **Planning**: `.planning/phases/13-standards-exercises/PLAN.md`, SUMMARY.md, VERIFICATION.md.\n\n## Phase 15: Standards Exercises â€” Error Heatmaps, Transcription & AI Analysis âœ…\n\n- **Status**: Completed.\n- **Goal**: Extend Phase 13 with error heatmaps (per measure, per exercise type: Scales â€¢ Guide Tones â€¢ Arpeggios), option to record written transcription of solo (mic or MIDI), and AI analysis of performance with advice and development suggestions.\n- **Requirements**: REQ-SBE-06 (error heatmaps), REQ-SBE-07 (record + written transcription), REQ-SBE-08 (AI analysis with advice and development suggestions).\n- **Delivered**: useStandardsExercise exposes statsByMeasure and exerciseType; StandardsExerciseHeatmapOverlay + useStandardsExerciseHeatmapStore; Lead Sheet shows exercise heatmap when Exercises panel open; useSoloTranscription + SoloTranscriptionPanel (Record solo â†’ note list + Copy); generateStandardsExerciseAnalysis in jazzTeacherLogic; \"Analyze performance\" button in StandardsExercisesPanel; unit tests for generateStandardsExerciseAnalysis.\n- **Completed Phase 14.1: SwiftF0 SOTA 2026 Integration**:\n  - Web Worker infrastructure for neural offloading (non-blocking inference).\n  - Instrument-aware hysteresis profiles (Vocals, Trumpet, Guitar).\n  - Atonal Gating (RMS + Confidence) to bridge noise gaps (\"chiff\" and \"pluck\").\n  - Regression Head support for sub-cent pitch resolution.\n  - Zero-Copy PCM pipeline sharing raw 16kHz audio with the worker.\n  - SwiftF0 enabled by default in `useHighPerformancePitch` with MPM fallback.\n",
  "roadmap_content": "# ITM Roadmap 2026\n\n## Phase 1: The \"Feedback\" Engine\n\n*Focus: Turning the app into an active listener and teacher.*\n\n- **Success Criteria**: Student can play along to a song and receive a numerical accuracy score based on microphone input with <10ms latency.\n- **Tasks**:\n  - [ ] Implement **High-Performance Pitch Detection**: Use **SwiftF0 (2026 SOTA)** for neural jazz-proof accuracy.\n  - [ ] Implement **Audio Worklet + SharedArrayBuffer Pattern**: Move pitch math to a separate thread or background worker to ensure 120Hz UI smoothness.\n  - [ ] Enable **MediaTrackConstraints.voiceIsolation**: Built-in browser AI for cleaning instrument input in noisy environments.\n  - [ ] Implement **Zustand Scoring Logic**: Real-time comparison of Mic Pitch to Tonal.js Chord Tones.\n  - [ ] Build **Guided Practice UI**: Component to manage the 15-minute routine timer and narrations.\n  - [ ] Integrate **Gemini Nano Analysis**: Hook that summarizes session performance into a pedagogical critique.\n  - [ ] Create **Performance Heatmap**: Visualization of where in the song the student succeeded/failed.\n\n## Phase 2: The \"Mastery Tree\" âœ…\n\n*Focus: Standardizing the 1,300 standards into a learning path.*\n\n- **Success Criteria**: A user can navigate a visual tree and unlock songs based on their performance data.\n- **Tasks**:\n  - [x] Implement **Song Tagging System**: Metadata for harmonic complexity.\n  - [x] Build **Visual Progress Tree**: UI component (SVG/Canvas) for song progression.\n  - [x] Implement **Key Cycle Routine**: Logic for tracking mastery across keys (Sonny Rollins approach).\n\n## Phase 3: The \"Sonic\" Layer âœ…\n\n*Focus: Moving from prototype audio to high-fidelity practice.*\n\n- **Success Criteria**: High-quality samples with a 3-track mixer for user control and studio-grade effects.\n- **Tasks**:\n  - [x] Build **Dynamic Mixer Component**: Separate volume controls for Bass, Drums, and Piano (PremiumMixer + Mute/Solo + Master Limiter/EQ).\n  - [x] Implement **Note Waterfall**: Real-time MIDI-to-Visual transcription layer (band engine, Transport sync, harmonic coloring).\n  - [x] Add **Tone Selection Spectrum**: Basic mic analysis feedback for instrument quality (ToneSpectrumAnalyzer + Acoustic Feedback warmth/brightness).\n\n## Phase 4: Cloud & Community âœ…\n\n*Focus: Scaling from local-first to a connected ecosystem.*\n\n- **Success Criteria**: Students can share licks and teachers can see their dashboards remotely.\n- **Tasks**:\n  - [x] Integrate **Supabase** for user profiles and progress synchronization.\n  - [x] Build **Teacher Dashboard UI**: Classroom management and student analytics.\n  - [x] Implement **Lick Social Feed**: Publishing system for converted licks.\n  - [x] Final **PWA Optimization**: Service workers and offline manifest.\n\n## Phase 5: The \"Director\" Engine âœ…\n\n*Focus: Adaptive curriculum driven by spaced repetition and context variation.*\n\n- **Success Criteria**: The AI \"Director\" schedules what to practice using FSRS (R, S, D) and varies timbre/instrument (e.g. Piano â†’ Cello â†’ Synth) to reduce context-dependency; teaching flow is data-driven and adaptive.\n- **Tasks**:\n  - [x] **FSRS integration**: Integrate FSRS (e.g. ts-fsrs) so each practice item has Retrievability (R), Stability (S), and Difficulty (D); schedule reviews and new material based on algorithm.\n  - [x] **Director service**: Central \"Director\" that consumes FSRS state and session context to decide next item (song, lick, key, exercise) and optional difficulty/pace.\n  - [x] **Context injection**: Director varies timbre/instrument for playback (Piano â†’ Cello â†’ Synth or internal patches) via the audio system so learning is not tied to a single sound; wire to globalAudio or JazzKiller playback layer.\n\n## Phase 6: Polish, Analytics & Launch\n\n*Focus: Production readiness, observability, and launch after Cloud & Community.*\n\n- **Success Criteria**: App is performance-audited, key flows are measurable, and onboarding supports new users; ready for public or classroom rollout.\n- **Tasks**:\n  - [ ] **Performance & bundle audit**: Core Web Vitals, bundle size, and critical path; fix regressions.\n  - [ ] **Analytics & events**: Instrument key actions (practice start/end, song unlock, lick publish) for product decisions.\n  - [ ] **Onboarding & first-run**: Guided first-time experience (e.g. pick instrument, try one song or lick).\n  - [ ] **Launch checklist**: Error boundaries, offline messaging, and doc/runbook for deploy and support.\n\n## Phase 7, 8, 10: Early Piano Engine Experiments (Superseded) ðŸ”„\n\n*Status: Reaches 'robotic' limitation. Logic moved to Phase 11.*\n\n## Phase 11: Pro Comping Engine (Templates & Grips) ðŸš€\n\n*Focus: Professional jazz piano feel via template-based rhythm and hand-shape (grip) dictionaries.*\n\n- **Success Criteria**: Engine plays 2-bar phrases (Standard, Sustain, Driving) using pre-curated rootless \"grips.\" Supports \"And of 4\" anticipation (next-chord peeking).\n- **Tasks**:\n  - [ ] **Grip Dictionary**: Implement `VOICING_LIBRARY` for Major, Minor, Dominant, Altered, and Half-Diminished.\n  - [ ] **Phrase-Template Logic**: Transition from random hit probabilities to 2-bar rhythmic templates.\n  - [ ] **Anticipation \"Push\"**: Implement look-ahead logic to steal chords from the next bar on 'and of 4' hits.\n  - [ ] **Bass-Aware Voicing**: Add automatic root-note support when the bass track is muted.\n  - [ ] **The \"Pivot Rule\"**: Normalize A/B form selection to keep voicings in \"The Pocket\" (C3-C5).\n\n## Phase 9: Mic Algorithm Upgrade (Stabilization & CREPE-Ready) âœ…\n\n*Focus: Eliminate neural jitter, octave jumps, and UI flicker in real-time pitch detection.*\n\n- **Success Criteria**: Stabilized pitch (confidence gate, running median, hysteresis) in Audio Worklet; usePitchTracker and ITM store consume smooth values; optional note + cents and instrument presets.\n- **Tasks**:\n  - [âœ…] **CrepeStabilizer**: Confidence gate (confidence < 0.85 â†’ hold last); running median (window 5); hysteresis (update only if |centDiff| > 20).\n  - [âœ…] **Worklet integration**: Run stabilizer inside pitch-processor.js; write stabilized frequency + confidence to SAB.\n  - [âœ…] **usePitchTracker / useITMPitchStore**: Read stabilized SAB; optional mic constraints (echoCancellation/noiseSuppression/autoGainControl false for jazz).\n  - [âœ…] **frequencyToNote**: Tonal.js-based note name + cents deviation; \"perfect intonation\" (Â±10 cents) for UI.\n  - [âœ…] **Instrument presets**: Clamp frequency by instrument (e.g. Double Bass 30â€“400 Hz, Trumpet 160â€“1100, Sax 100â€“900); optional Gemini hint for consistent sharp/flat.\n  - [âœ…] **Tests**: CrepeStabilizer, frequencyToNote, instrument presets; verification that UI no longer flickers and octave jumps are suppressed.\n\n## Phase 10: State-Machine Rhythmic Phrasing âœ…\n\n*Focus: Avoiding robotic loops via repetition penalties and Markov transitions.*\n\n- **Success Criteria**: The engine tracks its previous performance and actively penalizes repeating the same pattern, resulting in organic \"phrasing.\"\n- **Tasks**:\n  - [âœ…] **Pattern Memory**: Track deep history (last 4 patterns) in the engine.\n  - [âœ…] **Repetition Penalty Logic**: Apply exponential weight multipliers to recently played patterns.\n  - [âœ…] **The \"Push\" Awareness**: Correctly anticipate chord changes on the \"and of 4\".\n  - [âœ…] **Markov Transition Matrix**: Favor desirable rhythmic sequences (e.g. Sustain -> Standard).\n\n## Phase 11: Pro Drum Engine (Jack DeJohnette Style) âœ…\n\n*Focus: Limb independence and collaborative dynamics.*\n\n- **Success Criteria**: Generative drums that reactive to piano density; micro-timing (Push/Drag) for organic feel.\n- **Tasks**:\n  - [âœ…] **Broken-Time Ride**: Randomized skip notes for elastic pulse.\n  - [âœ…] **Collaborative Listening**: Simplify drum patterns when piano is \"busy\" (>0.8 density).\n  - [âœ…] **Micro-Timing**: Ride pushes (-4ms), Snare drags (+5ms), Â±1ms jitter.\n  - [âœ…] **Anchor Logic**: Strict Hi-Hat pedal on 2 & 4.\n\n## Phase 12: Walking Bass Engine (Target & Approach) ðŸš€\n\n*Focus: Teleological walking bassâ€”Beat 4 leads into the next chord.*\n\n- **Success Criteria**: 4-note line per bar with Beat 4 as chromatic or dominant approach; smooth voice leading across bar lines.\n- **Tasks**:\n  - [ ] **WalkingBassEngine**: Class with `generateWalkingLine(currentChord, nextChord)` (Anchor â†’ Bridge â†’ Bridge â†’ Approach); E1â€“G3 range.\n  - [ ] **Approach strategies**: Chromatic from below/above, 5th-of-destination; bridge notes as chord tones between Beat 1 and Beat 4.\n  - [ ] **Band integration**: useJazzBand generates line at beat 0, plays `line[beat]` for 0â€“3; state carried to next bar.\n\n## Phase 12.1: Bass Rhythm Variation ðŸš€\n\n*Focus: Organic bass variations (Skips, Rakes, Drops) to avoid robotic 4-note loops.*\n\n- **Success Criteria**: Every bar has a small chance (15-25%) to mutate from standard walking to a rhythmic variation; including \"The Skip\" (and-of-2), \"The Rake\" (triplet into 1), and \"The Drop\" (space).\n- **Tasks**:\n  - [ ] **BassRhythmVariator**: Implement class with `applyVariations(line, barIndex)` that transforms MIDI arrays into `BassEvent[]`.\n  - [ ] **Sample Switch Logic**: Update audio engine to use staccato envelope/sample for ghost/muted notes.\n  - [ ] **JazzBand Integration**: Refactor `useJazzBand` to consume `BassEvent[]` and handle sub-beat timing for variations.\n\n\n## Phase 13: Standards-Based Exercises (Scales, Guide Tones, Arpeggios) âœ…\n\n*Focus: **New module inside JazzKiller**â€”timed exercises over the standards (scales, guide tones, arpeggios) in sync with playback and the chart; support both mic and MIDI.*\n\n- **Success Criteria**: Inside JazzKiller, student can pick a standard (same library), choose an exercise type (Scales / Guide Tones / Arpeggios), play along with playback, and receive real-time evaluation; input can be mic or MIDI.\n- **Tasks**:\n  - [x] **Scale exercise**: Per-chord target scale from ChordScaleEngine; evaluate student input (mic/MIDI) against scale notes in time with chart and playback.\n  - [x] **Guide-tone exercise**: Per-chord target 3rd/7th from GuideToneCalculator; score hitting guide tones on downbeats (reuse/extend REQ-FB-02).\n  - [x] **Arpeggio exercise**: Per-chord chord tones as target; real-time evaluation in sync with playback.\n  - [x] **Unified input**: Single exercise engine consuming either mic pitch (useITMPitchStore / existing pipeline) or MIDI; same scoring logic for both.\n  - [x] **JazzKiller Exercises module**: New view/panel **inside JazzKiller** (same standard picker, same chart, same playback); select exercise type + standard, start playback, show real-time feedback; optional Director/FSRS integration.\n\n## Phase 14: Pitch Detection Latency (Break the Latency Wall) âœ…\n\n*Focus: Reduce delay between playing a note and UI updating; target <10ms with **SwiftF0**; architecture neural-ready.*\n\n- **Success Criteria**: Hop size 128; 16 kHz effective input (downsample in worklet); zero-copy circular buffer; no GC in hot path; optional hop throttle via processorOptions.\n- **Tasks**:\n  - [x] **16 kHz downsampling**: Native circular buffer of size ceil(1024 * sampleRate / 16000); linear-interp downsample to 1024; MPM runs at effective 16 kHz.\n  - [x] **Zero-copy circular buffer**: TypedArray + ptr; buffer.set(input, ptr) with wrap; no push/shift.\n  - [x] **Hop size 128**: Run inference every block (or every hopBlocks) once buffer is full; overlapping frames.\n  - [x] **Pre-allocated buffers**: tempNative, downsampled, nsdf; no allocations in process().\n  - [x] **SwiftF0 swap path**: Document in RESEARCH; when integrated, use SwiftF0 for ~40x speed vs CREPE with SOTA accuracy.\n\n## Phase 15: Standards Exercises â€” Error Heatmaps, Transcription & AI Analysis âœ…\n\n*Focus: Extend Phase 13 with error heatmaps (Scales â€¢ Guide Tones â€¢ Arpeggios), optional written transcription of the solo, and AI analysis with advice and development suggestions.*\n\n- **Success Criteria**: When playing over a standard (mic or MIDI), user can view error heatmaps by exercise type; optionally record a solo and get a written transcription; after a session (or on demand), receive AI analysis with advice and development suggestions.\n- **Tasks**:\n  - [x] **Error heatmaps**: Expose per-measure hit/miss from useStandardsExercise; show heatmap on lead sheet (overlay per measure: green/amber/red) via StandardsExerciseHeatmapOverlay and useStandardsExerciseHeatmapStore; filter by exercise type (Scales, Guide Tones, Arpeggios).\n  - [x] **Record solo & transcription**: In Standards Exercises, add \"Record solo\" (SoloTranscriptionPanel); capture timestamped notes (pitch + measure/beat) from mic or MIDI via useSoloTranscription; at end of recording produce written note list (Tonal.js). Tie to current standard and transport.\n  - [x] **AI analysis**: generateStandardsExerciseAnalysis(sessionData) in jazzTeacherLogic: input heatmap (hits/misses), optional transcription, accuracy, exercise type, standard, key; output AI text (Gemini Nano) with strengths/weaknesses, advice, development suggestions. \"Analyze performance\" button in StandardsExercisesPanel.\n## Phase 14.1: SwiftF0 SOTA 2026 Integration âœ…\n\n*Focus: Pro-grade neural pitch detection with instrument-aware post-processing.*\n\n- **Success Criteria**: Web Worker offloading of SwiftF0 (WASM/WebGPU); <5ms inference; instrument-specific hysteresis (Vocals/Trumpet/Guitar); sub-cent resolution via Regression Head.\n- **Tasks**:\n  - [x] **Neural Inference Worker**: `SwiftF0Worker.ts` with non-blocking polling of PCM RingBuffer.\n  - [x] **Instrument Hysteresis Library**: Distinct stability profiles for various jazz instruments.\n  - [x] **Atonal Gating (RMS)**: Transient bridging for \"chiff\" and pluck noise.\n  - [x] **Regression Head Logic**: Sub-cent refinement from bins 3-134.\n  - [x] **Unified Store Integration**: `useITMPitchStore` favors SwiftF0 with MPM fallback.\n",
  "requirements_content": "# ITM Requirements (2026 Roadmap)\n\n## Phase 1: The \"Feedback\" Engine\n\n### REQ-FB-01: Guided Practice Sessions\n\n- **Requirement**: Implement \"Guided Mode\" where Gemini Nano narrates a 15-minute routine for a specific song.\n- **Components**: Scales (5 mins), Guide Tones (5 mins), Soloing (5 mins).\n\n### REQ-FB-02: Active Scoring Logic\n\n- **Requirement**: Use pitch detection to calculate an \"Accuracy Score\" (0-100%) in real-time.\n- **Bonus**: Implement \"Target Note mastery\" bonuses (hitting 3rds and 7ths on downbeats).\n\n### REQ-FB-03: Nano-Powered Critique\n\n- **Requirement**: Post-session analysis by Gemini Nano identifying specific strengths and weaknesses (e.g., \"Consistently flat on the Bridge's II-V\").\n\n### REQ-FB-04: High-Performance Pitch Engine\n\n- **Requirement**: Implement a WASM-based neural pitch detector (**SwiftF0**) in an Audio Worklet or background worker.\n- **Performance**: Use `SharedArrayBuffer` for zero-latency communication with the React UI (PitchMemory + processorOptions.sab; public/worklets/pitch-processor.js).\n- **Input Quality**: Enable `voiceIsolation` constraints on microphone streams to filter out practice room noise.\n- **Status**: MPM in Worklet + SAB; **SwiftF0 integration verified as viable (SOTA 2026)**; architecture ready for neural swap. COOP/COEP in Vite server/preview.\n\n## Phase 2: The \"Mastery Tree\"\n\n### REQ-MT-01: Skill-Based Tagging\n- **Requirement**: Categorize 1,300+ standards by harmonic complexity (Diatonic, Secondary Dominants, Modal Interchange, etc.).\n\n### REQ-MT-02: The Progress Map\n- **Requirement**: Create a visual tree (Duolingo style) where students must \"Pass\" a song at specific BPM/Accuracy thresholds to unlock the next.\n\n### REQ-MT-03: Key Cycles (Rollins Routine)\n- **Requirement**: Automate \"Mastery\" tracking across multiple keys (e.g., must master in C, F, Bb, Eb to \"Pass\").\n\n## Phase 3: The \"Sonic\" Layer\n\n### REQ-SL-01: Dynamic Mixer\n- **Requirement**: 3-track faders for Aebersold Stems (Drums, Bass, Piano).\n- **Functionality**: Allow soloing/muting specific instruments for targeted practice.\n\n### REQ-SL-02: Visual Transcription\n- **Requirement**: Real-time \"Note Waterfall\" showing the shapes of jazz licks as they are played.\n\n### REQ-SL-03: Tone Matching\n- **Requirement**: Analyze mic input spectrum to detect tone quality (e.g., \"honking\" saxophone or \"muddy\" guitar).\n\n## Phase 4: Cloud & Community\n\n### REQ-CC-01: Teacher Dashboard\n- **Requirement**: Implementation of \"Classrooms\" via Supabase where teachers can monitor student progress (BPM, Heatmaps).\n\n### REQ-CC-02: Lick Sharing\n- **Requirement**: Allow students to publish/subscribe to Lick formulas from the Lick Converter.\n\n### REQ-CC-03: Mobile PWA\n- **Requirement**: Ensure full PWA compatibility for offline practice room use.\n\n## Phase 5: The \"Director\" Engine\n\n### REQ-DR-01: FSRS-Based Scheduling\n- **Requirement**: Use FSRS (Free Spaced Repetition Scheduler) so each practice item is modeled with Retrievability (R), Stability (S), and Difficulty (D). Input (reviews, new material) is processed by the algorithm; Director uses R/S/D to decide what to show next.\n\n### REQ-DR-02: Director Service\n- **Requirement**: A central \"Director\" component/service that consumes FSRS state and session context to select the next item (song, lick, key, exercise) and optional difficulty/pace for the student.\n\n### REQ-DR-03: Context Injection (Timbre/Instrument)\n- **Requirement**: Director varies timbre and instrument (e.g. Piano â†’ Cello â†’ Synth) via the app's audio system (internal patches) so learning is not context-dependent on a single sound.\n\n## Phase 6: Polish, Analytics & Launch\n\n### REQ-PL-01: Performance & Bundle\n- **Requirement**: Meet Core Web Vitals (LCP, FID/INP, CLS) and keep critical path lean; audit and fix regressions.\n\n### REQ-PL-02: Analytics & Events\n- **Requirement**: Instrument key user actions (practice start/end, song unlock, lick publish, teacher dashboard views) for product and growth decisions.\n\n### REQ-PL-03: Onboarding & First-Run\n- **Requirement**: First-time users get a short guided flow (e.g. instrument choice, try one song or lick) to reach â€œfirst valueâ€ quickly.\n\n### REQ-PL-04: Launch Readiness\n- **Requirement**: Error boundaries, clear offline/error messaging, and minimal deploy/support runbook.\n\n## Phase 7: Advanced Piano Engine\n\n### REQ-APE-01: Voice-Leading Engine\n\n- **Requirement**: Implement a stateful engine that selects the best voicing (Type A or B) based on the previous chord to minimize movement.\n- **Metric**: Use \"Taxi Cab\" distance (Manhattan distance) to score candidates.\n\n### REQ-APE-02: Chord DNA Model\n\n- **Requirement**: Expand chord parsing to identify \"Guide Tones\" (3rd, 7th) and extensions/alterations (9, 13, b9, #9, b13) suitable for rootless jazz voicings.\n\n### REQ-APE-03: Register Management (Soprano Anchor)\n\n- **Requirement**: Implement a penalty system for voicings exceeding a defined top range (e.g., G5) to prevent octaves from drifting upwards during transitions.\n\n### REQ-APE-04: Tritone Substitution\n\n- **Requirement**: Allow the engine to optionally substitute a dominant chord with its tritone substitute if it results in significantly smoother voice leading or desired tension.\n\n## Phase 8: Advanced Rhythm Engine\n\n### REQ-ARE-01: BPM-Aware Pattern Selection\n\n- **Requirement**: Implement a selection logic that favors specific rhythmic patterns based on BPM zones (Slow < 110, Medium 110-190, Fast > 190).\n- **Patterns**: Include Charleston, RedGarland, Pedal (Sustain), Anticipation (Push), and SparseStab.\n\n### REQ-ARE-02: Dynamic Articulation Control\n\n- **Requirement**: Automatically adjust note duration based on BPM (e.g., 16n staccato at > 180 BPM, 4n legato at < 120 BPM).\n- **Goal**: Maintain clarity and prevent muddiness at high tempos.\n\n### REQ-ARE-03: Energy-Driven Rhythmic Bias\n\n- **Requirement**: Use the \"Energy\" or \"Tension\" parameter to bias rhythmic density (e.g., high energy boosts Anticipation and RedGarland).\n\n### REQ-ARE-04: Implementation Architecture\n\n- **Requirement**: Create a standalone `RhythmEngine` class to encapsulate pattern definitions, probability weights, and articulation logic.\n\n## Phase 9: Mic Algorithm Upgrade (Stabilization & CREPE-Ready)\n\n### REQ-MA-01: Pitch Stabilization (Confidence + Median + Hysteresis)\n\n- **Requirement**: Apply state-space post-processing to raw pitch: (1) confidence gateâ€”if confidence < 0.85, hold last stable pitch; (2) running median over 5 frames to reject outliers and octave spikes; (3) hysteresisâ€”update reported pitch only if change exceeds 20 cents to prevent vibrato/flicker.\n- **Location**: CrepeStabilizer (TS for tests) and inline equivalent in Audio Worklet (pitch-processor.js) so SAB receives stabilized values.\n\n### REQ-MA-02: Worklet Writes Stabilized Pitch\n\n- **Requirement**: The Audio Worklet writes stabilized frequency and confidence to SharedArrayBuffer; all consumers (usePitchTracker, useITMPitchStore) read smooth values with zero main-thread pitch math.\n\n### REQ-MA-03: Frequency-to-Note and Perfect Intonation\n\n- **Requirement**: Map stabilized frequency to note name (Tonal.js) and cents deviation from equal temperament. If |centsDeviation| â‰¤ 10, expose \"perfect intonation\" for UI (e.g. green indicator).\n\n### REQ-MA-04: Jazz Instrument Presets\n\n- **Requirement**: Optional frequency clamping per instrument (Double Bass 30â€“400 Hz, Trumpet 160â€“1100, Sax 100â€“900, Guitar 80â€“1000, Voice 80â€“1200) to reject impossible values and room noise.\n\n### REQ-MA-05: Optional Center-of-Gravity and Viterbi\n\n- **Requirement**: (Enhancement) In detector, use weighted argmax (sum(prob_i * freq_i) / sum(prob_i)) to reduce octave jumps. Document Viterbi decoding over CREPE activation matrix as future enhancement when CREPE-WASM is integrated.\n\n## Phase 10: State-Machine Rhythmic Phrasing\n\n### REQ-SMR-01: Repetition Penalty System\n\n- **Requirement**: Implement a stateful tracking of the previous pattern to penalize immediate repetition (0.2x weight multiplier).\n- **Goal**: Force the engine to \"phrase\" by exploring different rhythmic options consecutively.\n\n### REQ-SMR-02: Pattern-Specific Resilience\n\n- **Requirement**: Allow \"Pedal\" (sustained) patterns to repeat with a lighter penalty (0.8x) to simulate common jazz \"pads\" or breathing moments.\n\n### REQ-SMR-03: Stateful Weighted Selection\n\n- **Requirement**: The selection logic must combine BPM zones, energy bias, and the repetition penalty into a single probability matrix per measure.\n\n## Phase 11: Pro Comping Engine (Templates & Grips)\n\n### REQ-PRO-01: Grip Dictionary Harmony\n\n- **Requirement**: Replace mathematical voicing generation with a pre-curated \"Grip Dictionary\" (offsets relative to Root).\n- **Categories**: Major7, Minor7, Dominant7, Altered Dominant, Half-Diminished.\n- **Forms**: Support \"A Form\" and \"B Form\" for each chord type.\n\n### REQ-PRO-02: Phrase Template Rhythm\n\n- **Requirement**: Replace 1-bar random hits with 2-bar \"Phrase Templates\" (Standard, Sustain, Driving).\n- **Goal**: Create consistent grooves that repeat and resolve like a real musician.\n\n### REQ-PRO-03: Rhythmic Anticipation (The \"Push\")\n\n- **Requirement**: Implement \"And of 4\" anticipation. The engine must peek at the next chord and play its voicing early if the template calls for an anticipation hit.\n\n### REQ-PRO-04: Bass-Assist Integration\n\n- **Requirement**: If the \"Bass\" track is muted, the piano engine must automatically prepend the Root note (transposed down) to its voicings to maintain harmonic clarity.\n\n### REQ-PRO-05: Pivot Rule Normalization\n\n- **Requirement**: Switch between A/B voicing forms based on proximity to a \"Range Center\" (Middle C) or the previous voicing to prevent erratic jumping.\n\n## Phase 12: Walking Bass Engine (Target & Approach)\n\n### REQ-WB-01: 4-Beat Strategy (Anchor, Direction, Pivot, Approach)\n\n- **Requirement**: Generate a 4-note walking line per bar: Beat 1 = anchor (root/nearest chord tone); Beat 4 = approach note to next chordâ€™s root (chromatic or dominant); Beats 2â€“3 = bridge notes (chord tones or scale steps between Beat 1 and Beat 4).\n- **Goal**: \"Pro\" feel via Beat 4 leading into the next bar (chromatic upper/lower or 5th-of-destination).\n\n### REQ-WB-02: WalkingBassEngine Class\n\n- **Requirement**: Standalone engine using tonal.js (Chord, Note) with `generateWalkingLine(currentChordSymbol, nextChordSymbol)` returning `number[]` (4 MIDI notes), stateful `lastNoteMidi` for continuity.\n- **Constraints**: E1 (28)â€“G3 (55) range; constrain notes that fall outside.\n\n### REQ-WB-03: Band Integration\n\n- **Requirement**: JazzKiller band (useJazzBand) uses the engine per bar: at beat 0 generate full line, cache, and play `line[beat]` for beats 0â€“3; last note of line updates state for next bar.\n\n## Phase 13: Standards-Based Exercises (Scales, Guide Tones, Arpeggios)\n\n*New **module inside JazzKiller** that delivers timed exercises over the standards: play scales, guide tones, or arpeggios in sync with playback and the chart. Uses existing mic detection and works for both mic and MIDI input.*\n\n### REQ-SBE-01: Scale Exercise Mode\n\n- **Requirement**: Exercise mode where the student plays the **appropriate scale** for the current chord in time with JazzKiller playback and the lead-sheet chart.\n- **Behavior**: Per measure (or per chord), the app knows the current chord from the standard; `ChordScaleEngine` (or equivalent) provides the correct scale; student input (mic or MIDI) is evaluated against that scale in real time.\n- **Sync**: Use existing `currentMeasureIndexSignal` / `currentBeatSignal` and chart so the â€œtarget scaleâ€ updates with the progression.\n\n### REQ-SBE-02: Guide-Tone Exercise Mode\n\n- **Requirement**: Exercise mode where the student plays the **correct guide tones** (3rd and 7th) for each chord in time with the standard.\n- **Behavior**: Per chord, use existing `GuideToneCalculator` (or AiContextService guide tones) as the target set; real-time scoring for hitting 3rd/7th on downbeats (or designated beats).\n- **Integration**: Reuse REQ-FB-02 â€œTarget Note masteryâ€ logic where applicable; extend to full chart so guide tones are chart-driven.\n\n### REQ-SBE-03: Arpeggio Exercise Mode\n\n- **Requirement**: Exercise mode where the student plays the **correct arpeggio** (chord tones) for each chord in time with the standard.\n- **Behavior**: Chord tones per chord from existing theory (e.g. Tonal.js `Chord.notes` or AiContextService `chordTones`); evaluate student input against these notes in real time, in sync with playback and chart.\n\n### REQ-SBE-04: Unified Input (Mic + MIDI)\n\n- **Requirement**: All three exercise modes (scales, guide tones, arpeggios) must work with **both microphone input** and **MIDI input**.\n- **Behavior**: Single â€œexercise engineâ€ that consumes either (1) pitch/MIDI from the existing mic pipeline (useITMPitchStore / pitch detection) or (2) MIDI from a connected device; same scoring and target logic for both.\n\n### REQ-SBE-05: Exercise UI and Feedback (JazzKiller module)\n\n- **Requirement**: **Inside JazzKiller**, a dedicated Exercises view/panel/tab where the user selects exercise type (Scales / Guide Tones / Arpeggios), picks a standard from the same JazzKiller library, starts playback (same band/chart), and sees real-time feedback (correct/incorrect, accuracy, target notes).\n- **Scope**: This is part of JazzKiller, not a separate app or top-level routeâ€”same standard picker, same lead sheet, same playback; exercises run over the selected standard.\n- **Optional**: Persist scores or integrate with Director/FSRS for â€œwhat to practice next.â€\n\n## Phase 15: Standards Exercises â€” Error Heatmaps, Transcription & AI Analysis\n\n*Extends Phase 13. When the user plays over a standard (mic or MIDI) in Scales / Guide Tones / Arpeggios mode, provide error heatmaps, optional written transcription of the solo, and AI analysis with advice and development suggestions.*\n\n### REQ-SBE-06: Error Heatmaps for Standards Exercises (Scales â€¢ Guide Tones â€¢ Arpeggios)\n\n- **Requirement**: Per-measure (and optionally per-chord) visualization of hit/miss for Standards Exercises.\n- **Behavior**: For each exercise type (Scales, Guide Tones, Arpeggios), record hits and misses by measure (and optionally by chord) during a session; expose this data for visualization.\n- **UI**: Option to show an **error heatmap** on the lead sheet (e.g. overlay per measure: green/amber/red by accuracy) or in a dedicated panel (e.g. bar chart or grid over measures). User can view heatmap by exercise type (Scales vs Guide Tones vs Arpeggios).\n- **Data**: Reuse or extend `statsByMeasure` (hits/misses per measure) from `useStandardsExercise`; optionally persist per standard + exercise type for historical comparison.\n\n### REQ-SBE-07: Record Written Transcription of Solo\n\n- **Requirement**: When the user is playing over a standard (mic or MIDI), offer an option to **record** the performance and produce a **written transcription** of the solo.\n- **Behavior**: In Standards Exercises (or a dedicated \"Solo over standard\" mode), user can start \"Record solo\"; the app captures timestamped notes (pitch + onset/offset or rhythm) from the same input pipeline (mic via pitch detection or MIDI). At end of recording (or on demand), produce a written transcription: note list (e.g. \"C4, E4, G4...\") and/or notation (e.g. ABC, MusicXML, or internal note+rhythm format for display).\n- **Scope**: Works for both mic and MIDI input; transcription is tied to the current standard and transport (measure/beat) so it can be aligned with the chart for display or export.\n\n### REQ-SBE-08: AI Analysis of Performance with Advice and Development Suggestions\n\n- **Requirement**: After a Standards Exercise session (or on demand), provide **AI analysis** of the performance with **advice** and **further development suggestions**.\n- **Input**: Performance data: error heatmap (per measure, per exercise type), optional written transcription, accuracy (overall and per section), exercise type (Scales / Guide Tones / Arpeggios), standard name, key.\n- **Output**: AI-generated text (Gemini Nano or API): summary of strengths/weaknesses, specific advice (e.g. \"Work on guide tones in the bridge\"), and development suggestions (e.g. \"Next: practice this tune in 3 keys\" or \"Focus on arpeggios in bars 17â€“24\").\n- **Integration**: Reuse `generatePerformanceCritique`-style flow (jazzTeacherLogic); extend or add a dedicated `generateStandardsExerciseAnalysis(sessionData)` that accepts exercise heatmap, transcription snippet, and exercise type and returns pedagogical feedback.\n\n## Technical Priorities\n1. **High**: Pitch-to-Theory Sync (Turns app from book into teacher).\n2. **Medium**: Gemini Nano Hint Loop (Ear training \"AHA!\" moments).\n3. **Medium**: Cloudflare R2 Audio Hosting (Fast stem loading).\n4. **Low**: Visual Geometry (p5.js aesthetics).\n"
}